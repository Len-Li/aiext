## 网页 LLM 解读助手（Chrome 扩展）

一个简单的 Chrome 插件：读取当前网页内容，通过你自己的 LLM 接口进行总结/解读，并在悬浮窗中展示结果。支持在设置页中配置多个 API 配置、API Key 和模型，提供流式对话、多语言界面、字体缩放、面板拖拽和缩放等高级功能。

### ✨ 核心功能

- **网页内容提取**：自动提取当前网页的标题、URL 和正文内容，发送给 LLM 进行解读。
- **多配置支持**：可保存多个 LLM 配置（API 地址、API Key、模型），并随时切换。
- **流式对话**：支持 Server-Sent Events (SSE) 流式响应，实时显示 LLM 生成内容。
- **悬浮窗聊天**：在网页上显示可拖拽、缩放、居中的悬浮窗，提供类似 ChatGPT 的交互体验。
- **多语言界面**：支持简体中文、英文、日文界面，可在设置中切换。
- **对话历史管理**：自动保存对话历史，支持按关键词搜索、按时间排序、批量删除。
- **字体大小调整**：可动态调整聊天内容的字体大小（10px‑20px）。
- **面板拖拽与缩放**：悬浮窗可任意拖拽位置，支持八个方向缩放，适应不同屏幕尺寸。
- **问答导航**：在历史问答对之间快速跳转（上一对/下一对）。
- **消息折叠**：长用户消息自动折叠，点击展开，节省屏幕空间。
- **暂停/继续**：流式生成过程中可随时暂停，也可继续生成。
- **LaTeX 公式渲染**：使用 KaTeX 在聊天内容中渲染数学公式（行内与块级）。
- **代码高亮**：使用 highlight.js 对代码块进行语法高亮（VSCode 风格）。
- **Markdown 渲染**：支持粗体、标题、列表、链接等基本 Markdown 语法。

### ⌨️ 快捷键

| 快捷键 | 功能 | 备注 |
|--------|------|------|
| 双击 `b` | 弹出/隐藏悬浮窗聊天框 | 在任意网页上快速双击字母 **b**（不在输入框中） |
| 双击 `v` | 将悬浮窗居中显示 | 悬浮窗已打开时，快速双击字母 **v** |
| 点击扩展图标 | 打开 popup 并触发解读 | 传统使用方式 |
| 悬浮窗内 `Enter` | 发送消息 | 焦点在输入框时按 Enter 发送（Shift+Enter 换行） |
| 点击 `↑` / `↓` 按钮 | 导航问答对 | 当有多个问答对时，跳转到上一个/下一个 |

### 📁 文件结构

- `manifest.json`：扩展配置（Manifest V3）
- `background.js`：Service Worker，负责调用 content script 获取网页内容、再请求 LLM 接口
- `content_script.js`：注入到网页中，提取可读文本（`document.body.innerText`）
- `popup.html` / `popup.js` / `popup.css`：工具按钮入口，点击后触发「解读当前网页」，展示结果
- `options.html` / `options.js` / `options.css`：设置页，可填写 API URL / API Key / 模型
- `overlay.js`：悬浮窗聊天界面，支持流式对话、多语言、字体缩放、面板拖拽和缩放
- `i18n.js` / `i18n-data.js`：国际化支持（中/英/日）
- `utils.js`：共享工具函数
- `img/`：图标（当前未提供，可自行添加 PNG 图标并与 `manifest.json` 中的路径对应）

### 🔧 如何在 Chrome 中加载

1. 打开 Chrome，访问 `chrome://extensions/`
2. 右上角打开 **开发者模式**
3. 点击 **“加载已解压的扩展程序”**
4. 选择本项目所在的文件夹（包含 `manifest.json` 的目录）
5. 加载成功后，会看到扩展图标（如无自定义图标则为默认图标）

### ⚙️ 首次使用前的配置

1. 在扩展列表里找到「网页 LLM 解读助手」
2. 点击「详情」→「扩展选项」或在 popup 中点击「设置」按钮
3. 在设置页中填写：
   - **API 地址（URL）**：你的 LLM 接口地址  
     - 示例（OpenAI 兼容）：`https://api.your-llm.com/v1/chat/completions`
   - **API Key**：你的密钥
   - **模型名称**：例如 `gpt-4.1`、`gpt-4o`、`qwen-max` 等
4. 点击「保存设置」

### 📡 当前默认的请求格式（可自定义）

在 `background.js` 中的 `callLLM` 函数里，默认使用 OpenAI Chat Completions 兼容格式：

- 请求方法：`POST`
- 请求体大致为：

```json
{
  "model": "你的模型名",
  "messages": [
    { "role": "system", "content": "你是一个帮助用户用简体中文解释网页内容的助手..." },
    { "role": "user", "content": "包含网页标题、URL 和正文内容的长文本" }
  ]
}
```

- 请求头中会附带：

```http
Authorization: Bearer <你的 API Key>
Content-Type: application/json
```

如果你的 LLM 接口不是 OpenAI 兼容的，只需要根据你的接口协议修改：

- `background.js` → `callLLM(pageData)` 中的 `fetch(apiUrl, { ... })` 部分：
  - URL / method / headers
  - body 的结构
  - 以及解析响应数据的逻辑（`data.choices[0].message.content` 等）

### 🚀 使用方式

#### 方式一：传统 Popup 解读
1. 打开任意网页
2. 点击浏览器工具栏中的「LLM 解读助手」图标
3. 在弹出的 popup 中点击 **「解读当前网页」**
4. 等待片刻，解读结果会显示在下方文本框中

#### 方式二：悬浮窗聊天模式（推荐）
1. 在任意网页上 **双击 `b`** 打开悬浮窗（或按 `Ctrl+Shift+L` 如果已实现）
2. 悬浮窗出现后，点击 **「解读本页」** 按钮，即可开始对话
3. 在底部输入框中输入问题，按 **Enter** 发送，享受流式回复
4. 使用面板右上角的按钮切换语言、调整字体、查看历史、打开设置
5. 拖拽标题栏可移动面板，拖拽边缘或角落可缩放面板
6. 双击 `v` 可将面板居中显示

### 🎛️ 悬浮窗详细功能

- **多配置切换**：下拉菜单选择不同的 LLM 配置（需先在设置页添加）。
- **流式对话**：实时显示 LLM 生成内容，可随时暂停/继续。
- **历史记录**：点击 📚 按钮打开历史面板，可搜索、查看、删除过往对话。
- **设置**：点击 ⚙️ 按钮打开设置面板，可添加/删除配置、切换语言、调整字体等。
- **字体缩放**：使用 `−` 和 `+` 按钮调整聊天内容字体大小。
- **问答导航**：使用 `↑` 和 `↓` 按钮在历史问答对之间跳转。
- **LaTeX 与代码高亮**：自动识别并渲染公式和代码块。

### 🔒 安全与隐私

- API Key、API 地址和模型名称保存在 `chrome.storage.sync` 中：
  - 会在你的浏览器个人配置中同步（同一账号的浏览器之间可能同步）
  - 不会上传到本扩展作者的任何服务器
- 网页内容会被发送到你配置的 LLM 接口，请确保你信任自己的后端服务，并在隐私敏感页面谨慎使用。

### 📝 最新优化（2025-12-12）

- **代码结构和模块化**：合并了 `background.js` 中重复的消息监听器，统一了历史记录相关消息处理。
- **错误处理和日志**：添加了 Service Worker 全局错误处理（`error` 和 `unhandledrejection`），改进了 `callLLM` 函数的错误消息和 60 秒超时机制。
- **性能优化**：为配置读取和页面数据获取添加了内存缓存，减少重复的存储访问和脚本执行。
- **代码一致性和可维护性**：移除了未使用的 `createStatusSetter` 重复定义，为关键函数添加了 JSDoc 注释，统一了代码风格。
- **国际化**：支持中/英/日三语界面，可通过悬浮窗设置切换。

## Author

Len Li